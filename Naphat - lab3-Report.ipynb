{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Recognition\n",
    "\n",
    "The objective of this lab is very simple, to recognize objects in images. You will be working with a well-known dataset called CIFAR-10.\n",
    "\n",
    "You can learn more about this dataset and download it here:\n",
    "\n",
    "https://www.cs.toronto.edu/~kriz/cifar.html\n",
    "\n",
    "In the webpage above, they also included a few publications based on CIFAR-10 data, which showed some amazing accuracies. The worst network on the page (a shallow convolutional neural network) can classify images with rouhgly 75% accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Write a function to load data\n",
    "\n",
    "The dataset webpage in the previous section also provide a simple way to load data from your harddrive using pickle. You may use their function for this exercise.\n",
    "\n",
    "Construct two numpy arrays for train images and train labels from data_batch_1 to data_batch_5. Then, construct two numpy arrays for test images, and test labels from test batch file. The original image size is 32 x 32 x 3. You may flatten the arrays so the final arrays are of size 1 x 3072."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict[b'data'],dict[b'labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "DATA_train =[]\n",
    "Label_train =[]\n",
    "DATA_TEST =[]\n",
    "Label_TEST=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,6):\n",
    "    Data,label=unpickle('data_batch_'+str(i))\n",
    "    DATA_train.extend(Data)\n",
    "    Label_train.extend(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_test,label_test =unpickle('test_batch')\n",
    "DATA_TEST.extend(Data_test)\n",
    "Label_TEST.extend(label_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_TRAIN =   50000 LABEL_TRAIN =  50000\n",
      "DATA_TEST  =   10000 LABEL_TEST  =  10000\n"
     ]
    }
   ],
   "source": [
    "print (\"DATA_TRAIN =  \",len(DATA_train),\"LABEL_TRAIN = \",len(Label_train))\n",
    "print (\"DATA_TEST  =  \",len(DATA_TEST),\"LABEL_TEST  = \",len(Label_TEST))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ผมได้เปลี่ยนภาพ โดนการอ่านไฟล์จาก ตัวอย่างโค้ดของ https://www.cs.toronto.edu/~kriz/cifar.html โดยมี  fuction unpickle มาให้อยู่แล้วแต่ผมได้เติม\n",
    "# ตรง returnเข้าไปให้ returnออกมาเป็น 2ตัวเลย ฝั่งซ้ายเป็นรูปภาพ โดยจะได้ค่าจากภาพและ label\n",
    "# โดยผมอ่าน data_batch_1-5 แล้ว extend เข้าไปใน DATAtrain และ LAbeltrain\n",
    "#ทำเช่นนี้เหมือนกัน แต่ ทำใน DATATESTด้วย\n",
    "# เป็น DATA_TRAIN มี50000 รูป และ label จะมีเท่ากันโดยเรียงlabelตามลำดับในlist เหมือนกัน\n",
    "# เป็น DATA_TEST มี10000 รูป และ label จะมีเท่ากันโดยเรียงลำดับ labelคู่กับรูปภาพ เช่นกัน\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Classify Dogs v.s. Cats\n",
    "\n",
    "Let’s start simple by creating logistic regression model to classify images. We will select only two classes of images for this exercise.\n",
    "\n",
    "1. From 50,000 train images and 10,000 test images, we want to reduce the data size. Write code to filter only dog images (label = 3) and cat images (label = 5).\n",
    "2. Create a logistic regression model to classify cats and dogs. Report your accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DOGCAT_TRAIN =[]\n",
    "LABEL_DOGCAT_TRAIN =[]\n",
    "DATA_DOGCAT_TEST =[]\n",
    "LABEL_DOGCAT_TEST =[]\n",
    "for i in range(0,len(Label_train)):\n",
    "    if Label_train[i]==3 or Label_train[i] ==5 :\n",
    "        DATA_DOGCAT_TRAIN.append(DATA_train[i])\n",
    "        LABEL_DOGCAT_TRAIN.append(Label_train[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(Label_TEST)):\n",
    "    if Label_TEST[i]==3 or Label_TEST[i] ==5 :\n",
    "        DATA_DOGCAT_TEST.append(DATA_TEST[i])\n",
    "        LABEL_DOGCAT_TEST.append(Label_TEST[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_TRAIN_DOGCAT =   10000 LABEL_TRAIN_DOGCAT =  10000\n",
      "DATA_TEST_DOGCAT  =   2000 LABEL_TEST_DOGCAT  =  2000\n"
     ]
    }
   ],
   "source": [
    "print (\"DATA_TRAIN_DOGCAT =  \",len(DATA_DOGCAT_TRAIN),\"LABEL_TRAIN_DOGCAT = \",len(LABEL_DOGCAT_TRAIN))\n",
    "print (\"DATA_TEST_DOGCAT  =  \",len(DATA_DOGCAT_TEST),\"LABEL_TEST_DOGCAT  = \",len(LABEL_DOGCAT_TEST))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5325"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DOGCAT_TRAIN_ARRAY =np.asarray(DATA_DOGCAT_TRAIN)\n",
    "DOGCAT_TEST_ARRAY =np.asarray(DATA_DOGCAT_TEST)\n",
    "LOGIS_Model = LogisticRegression()\n",
    "LOGIS_Model.fit(DOGCAT_TRAIN_ARRAY,LABEL_DOGCAT_TRAIN)\n",
    "LABEL_DOGCAT_PRED= LOGIS_Model.predict(DOGCAT_TEST_ARRAY)\n",
    "accuracy_score(y_pred = LABEL_DOGCAT_PRED,y_true = LABEL_DOGCAT_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#ส่วนข้อนี้ ผมแยก label =3 และ label=5 \n",
    "#โดยรันผ่าน forloop ทำไปเรื่อยๆเช็คทุกรูปภาพ แต่เช็คผ่านlabel\n",
    "# หากมี label =3,5 จะให้ append เข้าlist ใหม่ทั้ง ภาพและ label\n",
    "# ทำเช่นนี้ทั้งtrain และ test จะทำให้ listใหม่ที่ได้มาจะเป็นlistที่มีlabel\n",
    "# เพียงแค่3 และ 5 โดยเหลือ\n",
    "#DATA_TRAIN_DOGCAT =   10000 LABEL_TRAIN_DOGCAT =  10000\n",
    "#DATA_TEST_DOGCAT  =   2000 LABEL_TEST_DOGCAT  =  2000\n",
    "#หลังจากนั้นผมไปแปลงเป็น numpy array เพื่อเข้าไป fit model\n",
    "# model logisticregression \n",
    "# ตามโจทย์ หลังจาก fit ด้วย data ,label ของtrainแล้ว\n",
    "#ลอง predict label ด้วย data_test หลังจากนั้นนำมาเทียบกับ\n",
    "# label_test_dogcat เพื่อหา accuracy และได้0.5325"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. The Real Challenge\n",
    "\n",
    "The majority of your score for this lab will come from this real challenge. You are going to construct a neural network model to classify 10 classes of images from CIFAR-10 dataset. You will get half the credits for this one if you complete the assignment, and will get another half if you can exceed the target accuracy of 75%. (You may use any combination of sklearn, opencv, or tensorflow to do this exercise).\n",
    "\n",
    "Design at least 3 variants of neural network models. Each model should have different architectures. (Do not vary just a few parameters, the architecture of the network must change in each model). In your notebook, explain your experiments in details and display the accuracy score for each experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "MLP_CLASSI = MLPClassifier(hidden_layer_sizes = 30)\n",
    "MLP_CLASSI.fit(DATA_train,Label_train)\n",
    "PRED_MLP = MLP_CLASSI.predict(DATA_TEST)\n",
    "accuracy_score(Label_TEST,PRED_MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ข้อนี้ผมทำการทำmodelขึ้นมา3แบบ\n",
    "#แบบแรกใช้ mlp โดยมี hiddenlayer =30\n",
    "#และไปเทียบกับ test และ train  data ของเรา\n",
    "#ทำเหมือนข้อบนๆคือ fit train และ\n",
    "# นำ model ไป predict ไฟล์ test และเปรียบเทียบ\n",
    "# accuracy ได้เพียง 0.1 = 10%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1331"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "MLP_CLASSI = MLPClassifier(hidden_layer_sizes = 800)\n",
    "MLP_CLASSI.fit(DATA_train,Label_train)\n",
    "PRED_MLP = MLP_CLASSI.predict(DATA_TEST)\n",
    "accuracy_score(Label_TEST,PRED_MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#แบบ2คือ ทำเหมือนmodelแบบแรกเปลี่ยน hiddenlayer30เป็น800\n",
    "# ได้ค่า accuracyขึ้นมาเป็น 0.133= 13%\n",
    "#ขึ้นมาเพียงนิดเดียว\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import BatchNormalization\n",
    "\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 8\n",
    "numpy.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_train = np.array(DATA_train)\n",
    "LABEL_train = np.array(Label_train)\n",
    "DATA_test = np.array(DATA_TEST)\n",
    "LABEL_test = np.array(Label_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_train = DATA_train.reshape((50000,32,32,3))\n",
    "DATA_test = DATA_test.reshape((10000,32,32,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_train = DATA_train.astype('float32')\n",
    "DATA_test = DATA_test.astype('float32')\n",
    "DATA_train = DATA_train / 255.0\n",
    "DATA_test = DATA_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_train = np_utils.to_categorical(LABEL_train)\n",
    "LABEL_test = np_utils.to_categorical(LABEL_test)\n",
    "num_classes = LABEL_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 32, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 32, 16, 16)        64        \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 32, 16, 16)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 32, 16, 16)        64        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 32, 8, 8)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 32, 8, 8)          1056      \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 32, 8, 8)          32        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 32, 4, 4)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 279,146\n",
      "Trainable params: 279,066\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3,3), input_shape=(32,32,3), padding='same', activation='relu', data_format='channels_last'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(32, (1, 1), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/35\n",
      "50000/50000 [==============================] - 58s 1ms/step - loss: 0.6736 - acc: 0.7574 - val_loss: 1.3017 - val_acc: 0.5977\n",
      "Epoch 2/35\n",
      "50000/50000 [==============================] - 54s 1ms/step - loss: 0.6622 - acc: 0.7586 - val_loss: 1.3161 - val_acc: 0.5905\n",
      "Epoch 3/35\n",
      "50000/50000 [==============================] - 55s 1ms/step - loss: 0.6425 - acc: 0.7697 - val_loss: 1.2776 - val_acc: 0.6004\n",
      "Epoch 4/35\n",
      "50000/50000 [==============================] - 54s 1ms/step - loss: 0.6329 - acc: 0.7730 - val_loss: 1.2499 - val_acc: 0.6033\n",
      "Epoch 5/35\n",
      "50000/50000 [==============================] - 54s 1ms/step - loss: 0.6308 - acc: 0.7725 - val_loss: 1.2592 - val_acc: 0.6022\n",
      "Epoch 6/35\n",
      "50000/50000 [==============================] - 54s 1ms/step - loss: 0.6097 - acc: 0.7791 - val_loss: 1.3139 - val_acc: 0.6037\n",
      "Epoch 7/35\n",
      "50000/50000 [==============================] - 54s 1ms/step - loss: 0.5973 - acc: 0.7852 - val_loss: 1.3414 - val_acc: 0.5905\n",
      "Epoch 8/35\n",
      "50000/50000 [==============================] - 54s 1ms/step - loss: 0.5908 - acc: 0.7854 - val_loss: 1.3088 - val_acc: 0.6004\n",
      "Epoch 9/35\n",
      "50000/50000 [==============================] - 55s 1ms/step - loss: 0.5825 - acc: 0.7904 - val_loss: 1.3315 - val_acc: 0.5993\n",
      "Epoch 10/35\n",
      "50000/50000 [==============================] - 56s 1ms/step - loss: 0.5749 - acc: 0.7930 - val_loss: 1.3955 - val_acc: 0.5945\n",
      "Epoch 11/35\n",
      "50000/50000 [==============================] - 54s 1ms/step - loss: 0.5693 - acc: 0.7926 - val_loss: 1.3060 - val_acc: 0.5949\n",
      "Epoch 12/35\n",
      "50000/50000 [==============================] - 54s 1ms/step - loss: 0.5592 - acc: 0.7995 - val_loss: 1.2892 - val_acc: 0.5918\n",
      "Epoch 13/35\n",
      "50000/50000 [==============================] - 54s 1ms/step - loss: 0.5497 - acc: 0.8017 - val_loss: 1.3896 - val_acc: 0.5986\n",
      "Epoch 14/35\n",
      "50000/50000 [==============================] - 58s 1ms/step - loss: 0.5425 - acc: 0.8030 - val_loss: 1.3687 - val_acc: 0.5918\n",
      "Epoch 15/35\n",
      "50000/50000 [==============================] - 54s 1ms/step - loss: 0.5328 - acc: 0.8068 - val_loss: 1.4608 - val_acc: 0.5980\n",
      "Epoch 16/35\n",
      "50000/50000 [==============================] - 56s 1ms/step - loss: 0.5313 - acc: 0.8093 - val_loss: 1.4539 - val_acc: 0.6010\n",
      "Epoch 17/35\n",
      "50000/50000 [==============================] - 56s 1ms/step - loss: 0.5270 - acc: 0.8074 - val_loss: 1.4227 - val_acc: 0.5980\n",
      "Epoch 18/35\n",
      "50000/50000 [==============================] - 57s 1ms/step - loss: 0.5254 - acc: 0.8114 - val_loss: 1.3772 - val_acc: 0.5914\n",
      "Epoch 19/35\n",
      "50000/50000 [==============================] - 55s 1ms/step - loss: 0.5146 - acc: 0.8116 - val_loss: 1.3745 - val_acc: 0.5905\n",
      "Epoch 20/35\n",
      "50000/50000 [==============================] - 54s 1ms/step - loss: 0.5110 - acc: 0.8152 - val_loss: 1.4149 - val_acc: 0.5964\n",
      "Epoch 21/35\n",
      "50000/50000 [==============================] - 53s 1ms/step - loss: 0.5043 - acc: 0.8176 - val_loss: 1.4205 - val_acc: 0.5944\n",
      "Epoch 22/35\n",
      "50000/50000 [==============================] - 54s 1ms/step - loss: 0.4983 - acc: 0.8203 - val_loss: 1.4035 - val_acc: 0.5948\n",
      "Epoch 23/35\n",
      "50000/50000 [==============================] - 53s 1ms/step - loss: 0.4965 - acc: 0.8199 - val_loss: 1.3960 - val_acc: 0.5905\n",
      "Epoch 24/35\n",
      "50000/50000 [==============================] - 53s 1ms/step - loss: 0.4982 - acc: 0.8212 - val_loss: 1.4970 - val_acc: 0.5963\n",
      "Epoch 25/35\n",
      "50000/50000 [==============================] - 54s 1ms/step - loss: 0.4893 - acc: 0.8231 - val_loss: 1.5243 - val_acc: 0.5898\n",
      "Epoch 26/35\n",
      "50000/50000 [==============================] - 53s 1ms/step - loss: 0.4807 - acc: 0.8259 - val_loss: 1.5915 - val_acc: 0.5839\n",
      "Epoch 27/35\n",
      "50000/50000 [==============================] - 53s 1ms/step - loss: 0.4787 - acc: 0.8263 - val_loss: 1.5173 - val_acc: 0.5992\n",
      "Epoch 28/35\n",
      "50000/50000 [==============================] - 52s 1ms/step - loss: 0.4829 - acc: 0.8262 - val_loss: 1.5013 - val_acc: 0.5877\n",
      "Epoch 29/35\n",
      "50000/50000 [==============================] - 53s 1ms/step - loss: 0.4736 - acc: 0.8293 - val_loss: 1.5738 - val_acc: 0.5834\n",
      "Epoch 30/35\n",
      "50000/50000 [==============================] - 53s 1ms/step - loss: 0.4690 - acc: 0.8316 - val_loss: 1.5251 - val_acc: 0.5783\n",
      "Epoch 31/35\n",
      "50000/50000 [==============================] - 52s 1ms/step - loss: 0.4613 - acc: 0.8324 - val_loss: 1.5896 - val_acc: 0.5906\n",
      "Epoch 32/35\n",
      "50000/50000 [==============================] - 53s 1ms/step - loss: 0.4643 - acc: 0.8317 - val_loss: 1.5589 - val_acc: 0.5939\n",
      "Epoch 33/35\n",
      "50000/50000 [==============================] - 53s 1ms/step - loss: 0.4519 - acc: 0.8352 - val_loss: 1.5866 - val_acc: 0.5910\n",
      "Epoch 34/35\n",
      "50000/50000 [==============================] - 52s 1ms/step - loss: 0.4601 - acc: 0.8338 - val_loss: 1.4815 - val_acc: 0.5951\n",
      "Epoch 35/35\n",
      "50000/50000 [==============================] - 54s 1ms/step - loss: 0.4550 - acc: 0.8356 - val_loss: 1.4538 - val_acc: 0.5914\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x273f2e4d390>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(DATA_train,LABEL_train, epochs=35, batch_size=32,validation_data=(DATA_test,LABEL_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 59.14%\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of the model\n",
    "scores = model.evaluate(DATA_test, LABEL_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ขั้นตอนสุดท้ายผมทำ cnn โดยมีเรฟเฟอเร้นจาก\n",
    "# https://machinelearningmastery.com/object-recognition-convolutional-neural-networks-keras-deep-learning-library/\n",
    "#และปรับเปรียบค่า model ให้ค่า accuracyสูงขึ้น และทำไปทั้งหมด 35 รอบ\n",
    "# โดยผมConfig Number of layer , Number of Neural , Activation Fucntion for  Neural Network Model\n",
    "#ไว้แล้ว หลังจากนั้น ก็รันและได้ค่า accuracy ที่สูงขึ้นจาก13%\n",
    "#สูงมามากถึง 59% หากเรารันจำนวนรอบมากกว่านี้จะได้% ที่สูงมากกว่านี้ \t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
